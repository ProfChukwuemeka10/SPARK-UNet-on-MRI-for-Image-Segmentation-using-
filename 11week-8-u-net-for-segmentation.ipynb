{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARK Tutorials 2025\n",
    "## BrainðŸ§  Tumor Segmentation (PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Intro This Notebook is for experimental purpose, Studying U-Net Architecture and Image Segmentation task flow.\n",
    "##### Reference : [Lee etal](https://doi.org/10.1016/j.dib.2024.111159); [UNet](https://github.com/zhixuhao/unet); [Thomas Brox](https://arxiv.org/pdf/1505.04597)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:red;color:white;font-size:22px;text-align:center;border-radius:10px 10px;font-weight:bold;border:2px solid black\">Brain MRI Detector | Segmentation | Using UNet</p>\n",
    "\n",
    "<center><img src= \"https://www.mayoclinic.org/-/media/kcms/gbs/patient-consumer/images/2014/10/30/15/17/mcdc7_brain_cancer-8col.jpg\" alt =\"Brain-MRI\" style='width:300px;'></center>\n",
    "\n",
    "**Image source** : Mayo Clinic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Index\n",
    "\n",
    "* [Introduction](#1)\n",
    "* [What is Image Segmentation?](#1.1)\n",
    "* [EDA](#2)\n",
    "* [Image Visualization](#2.1)\n",
    "* [Data Generator](#3)\n",
    "* [Build UNet](#4)\n",
    "    * [UNet Architecture](#4.1)\n",
    "* [UNet Implementation](#5)    \n",
    "    * [Callbacks](#5.1)\n",
    "    * [Performance Metrics](#5.2)\n",
    "    * [Model Fit](#5.3)\n",
    "    * [Save UNet Model](#5.4)\n",
    "* [Evaluation](#6)\n",
    "* [Prediction](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:22px\">Introduction</span> <a id=1></a> \n",
    "A brain tumor is a mass or growth of abnormal cells in your brain.Many different types of brain tumors exist. Some brain tumors are noncancerous (benign), and some brain tumors are cancerous (malignant). Brain tumors can begin in your brain (primary brain tumors), or cancer can begin in other parts of your body and spread to your brain as secondary (metastatic) brain tumors.\n",
    "\n",
    "How quickly a brain tumor grows can vary greatly. The growth rate as well as the location of a brain tumor determines how it will affect the function of your nervous system.\n",
    "\n",
    "Brain tumor treatment options depend on the type of brain tumor you have, as well as its size and location. <br>\n",
    "**Source credits** : [Mayo Clinic](https://www.mayoclinic.org/diseases-conditions/brain-tumor/symptoms-causes/syc-20350084)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:22px\">What is Image Segmentation?</span> <a id=1.1></a> <br> \n",
    " *  The objective of the Image Segmentation is to classify each pixel of an image with the class it represents, by predicting each pixel in image. <br>\n",
    " *  Here in this notebook,we will implement the U-Net model, its a U-shaped architecture (in keras). \n",
    "We will also apply our model to a Brain MRI tumor detection problem to see how it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:22px\">Segmentation Models Pytorch, torchmetrics installation</span> <a id=1.1.1></a> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:03.496012Z",
     "iopub.status.busy": "2025-04-11T14:24:03.495698Z",
     "iopub.status.idle": "2025-04-11T14:24:03.619014Z",
     "shell.execute_reply": "2025-04-11T14:24:03.617936Z",
     "shell.execute_reply.started": "2025-04-11T14:24:03.495983Z"
    }
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:29.694637Z",
     "iopub.status.busy": "2025-04-11T14:24:29.694219Z",
     "iopub.status.idle": "2025-04-11T14:24:46.282168Z",
     "shell.execute_reply": "2025-04-11T14:24:46.281100Z",
     "shell.execute_reply.started": "2025-04-11T14:24:29.694598Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -qqq segmentation-models-pytorch \n",
    "!pip install segmentation-models-pytorch torch torchvision\n",
    "!pip install -qqq torchmetrics\n",
    "!pip install -U git+https://github.com/qubvel/segmentation_models.pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:22px\">Import Libraries</span> <a id=1.1.1></a> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:46.283971Z",
     "iopub.status.busy": "2025-04-11T14:24:46.283680Z",
     "iopub.status.idle": "2025-04-11T14:24:46.287483Z",
     "shell.execute_reply": "2025-04-11T14:24:46.286560Z",
     "shell.execute_reply.started": "2025-04-11T14:24:46.283947Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:46.289084Z",
     "iopub.status.busy": "2025-04-11T14:24:46.288867Z",
     "iopub.status.idle": "2025-04-11T14:24:58.698606Z",
     "shell.execute_reply": "2025-04-11T14:24:58.697875Z",
     "shell.execute_reply.started": "2025-04-11T14:24:46.289057Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import gc\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "from skimage import io\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.datasets import SimpleOxfordPetDataset\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from IPython.display import display\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:58.699754Z",
     "iopub.status.busy": "2025-04-11T14:24:58.699448Z",
     "iopub.status.idle": "2025-04-11T14:24:58.744177Z",
     "shell.execute_reply": "2025-04-11T14:24:58.743473Z",
     "shell.execute_reply.started": "2025-04-11T14:24:58.699727Z"
    }
   },
   "outputs": [],
   "source": [
    "start_time = datetime.now() \n",
    "img_data = pd.read_csv('/kaggle/input/lgg-mri-segmentation/kaggle_3m/data.csv') # mask data?\n",
    "img_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:58.745279Z",
     "iopub.status.busy": "2025-04-11T14:24:58.744986Z",
     "iopub.status.idle": "2025-04-11T14:24:58.766566Z",
     "shell.execute_reply": "2025-04-11T14:24:58.765794Z",
     "shell.execute_reply.started": "2025-04-11T14:24:58.745245Z"
    }
   },
   "outputs": [],
   "source": [
    "img_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:58.767743Z",
     "iopub.status.busy": "2025-04-11T14:24:58.767456Z",
     "iopub.status.idle": "2025-04-11T14:24:58.784399Z",
     "shell.execute_reply": "2025-04-11T14:24:58.783717Z",
     "shell.execute_reply.started": "2025-04-11T14:24:58.767723Z"
    }
   },
   "outputs": [],
   "source": [
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:58.787292Z",
     "iopub.status.busy": "2025-04-11T14:24:58.787080Z",
     "iopub.status.idle": "2025-04-11T14:24:59.823532Z",
     "shell.execute_reply": "2025-04-11T14:24:59.822815Z",
     "shell.execute_reply.started": "2025-04-11T14:24:58.787274Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = []\n",
    "for sub_dir_path in glob.glob(\"/kaggle/input/lgg-mri-segmentation/kaggle_3m/\"+\"*\"):\n",
    "    try:\n",
    "        dir_name = sub_dir_path.split('/')[-1]\n",
    "        for filename in os.listdir(sub_dir_path):\n",
    "            mask_path = sub_dir_path + '/' + filename\n",
    "            data_path.extend([dir_name, mask_path])\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:59.825229Z",
     "iopub.status.busy": "2025-04-11T14:24:59.824959Z",
     "iopub.status.idle": "2025-04-11T14:24:59.828566Z",
     "shell.execute_reply": "2025-04-11T14:24:59.827826Z",
     "shell.execute_reply.started": "2025-04-11T14:24:59.825208Z"
    }
   },
   "outputs": [],
   "source": [
    "filenames = data_path[::2]\n",
    "masks = data_path[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:59.829468Z",
     "iopub.status.busy": "2025-04-11T14:24:59.829236Z",
     "iopub.status.idle": "2025-04-11T14:24:59.851985Z",
     "shell.execute_reply": "2025-04-11T14:24:59.851282Z",
     "shell.execute_reply.started": "2025-04-11T14:24:59.829449Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"patient_id\": filenames,\"img_path\": masks})\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:59.853124Z",
     "iopub.status.busy": "2025-04-11T14:24:59.852823Z",
     "iopub.status.idle": "2025-04-11T14:24:59.856398Z",
     "shell.execute_reply": "2025-04-11T14:24:59.855749Z",
     "shell.execute_reply.started": "2025-04-11T14:24:59.853102Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Quiz: Filtering DataFrames in Pandas\n",
    "\n",
    "# # Given a DataFrame `df` with a column 'img_path', which contains file paths,\n",
    "# # we want to filter images and their corresponding masks.\n",
    "\n",
    "# # Question:\n",
    "# # How can we separate rows where 'img_path' contains \"mask\" from those that do not?\n",
    "\n",
    "# # Your Task:\n",
    "# # Fill in the missing code to correctly filter `original_img` and `mask_img`.\n",
    "\n",
    "# # Your code here:\n",
    "# original_img = df[_________________________]\n",
    "# mask_img = df[_________________________]\n",
    "\n",
    "# # Check your answer\n",
    "# print(f\"Number of original images: {len(original_img)}\")\n",
    "# print(f\"Number of mask images: {len(mask_img)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:59.857496Z",
     "iopub.status.busy": "2025-04-11T14:24:59.857232Z",
     "iopub.status.idle": "2025-04-11T14:24:59.878116Z",
     "shell.execute_reply": "2025-04-11T14:24:59.877470Z",
     "shell.execute_reply.started": "2025-04-11T14:24:59.857450Z"
    }
   },
   "outputs": [],
   "source": [
    "original_img = df[~df['img_path'].str.contains(\"mask\")]\n",
    "mask_img = df[df['img_path'].str.contains(\"mask\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:59.878941Z",
     "iopub.status.busy": "2025-04-11T14:24:59.878756Z",
     "iopub.status.idle": "2025-04-11T14:24:59.890423Z",
     "shell.execute_reply": "2025-04-11T14:24:59.889700Z",
     "shell.execute_reply.started": "2025-04-11T14:24:59.878924Z"
    }
   },
   "outputs": [],
   "source": [
    "original_img, mask_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:59.891708Z",
     "iopub.status.busy": "2025-04-11T14:24:59.891382Z",
     "iopub.status.idle": "2025-04-11T14:24:59.910569Z",
     "shell.execute_reply": "2025-04-11T14:24:59.909755Z",
     "shell.execute_reply.started": "2025-04-11T14:24:59.891677Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs = sorted(original_img[\"img_path\"].values, key=lambda x : int(x[89:-4]))\n",
    "masks = sorted(mask_img[\"img_path\"].values, key=lambda x : int(x[89:-9]))\n",
    "\n",
    "# Sorting check\n",
    "idx = random.randint(0, len(imgs)-1)\n",
    "print(\"Image path:\", imgs[idx], \"\\nMask path:\", masks[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:59.911622Z",
     "iopub.status.busy": "2025-04-11T14:24:59.911410Z",
     "iopub.status.idle": "2025-04-11T14:24:59.932238Z",
     "shell.execute_reply": "2025-04-11T14:24:59.931395Z",
     "shell.execute_reply.started": "2025-04-11T14:24:59.911603Z"
    }
   },
   "outputs": [],
   "source": [
    "mri_df = pd.DataFrame({\"patient_id\": original_img.patient_id.values,\"img_path\": imgs,\n",
    "                           'mask_path':masks})\n",
    "mri_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:59.933585Z",
     "iopub.status.busy": "2025-04-11T14:24:59.933231Z",
     "iopub.status.idle": "2025-04-11T14:24:59.947196Z",
     "shell.execute_reply": "2025-04-11T14:24:59.946385Z",
     "shell.execute_reply.started": "2025-04-11T14:24:59.933554Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_diagnosis(img_path):\n",
    "    value = np.max(cv2.imread(img_path))\n",
    "    if value > 0 : \n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:59.948198Z",
     "iopub.status.busy": "2025-04-11T14:24:59.947971Z",
     "iopub.status.idle": "2025-04-11T14:24:59.966188Z",
     "shell.execute_reply": "2025-04-11T14:24:59.965383Z",
     "shell.execute_reply.started": "2025-04-11T14:24:59.948178Z"
    }
   },
   "outputs": [],
   "source": [
    "mri_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:59.967598Z",
     "iopub.status.busy": "2025-04-11T14:24:59.967260Z",
     "iopub.status.idle": "2025-04-11T14:24:59.978273Z",
     "shell.execute_reply": "2025-04-11T14:24:59.977634Z",
     "shell.execute_reply.started": "2025-04-11T14:24:59.967569Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Quiz: Applying Functions and Data Type Conversion in Pandas\n",
    "\n",
    "# # Given a DataFrame `mri_df` with a column 'mask_path',\n",
    "# # we want to apply a function `get_diagnosis()` to extract diagnosis information\n",
    "# # and store it in a new column called 'mask'. \n",
    "# # Additionally, we want to ensure that 'mask_path' is stored as a string.\n",
    "\n",
    "# # Question:\n",
    "# # Fill in the missing parts of the code to correctly apply a function and convert data types.\n",
    "\n",
    "# # Your Task:\n",
    "# # Complete the missing parts of the code.\n",
    "\n",
    "# # Define the function (Assume `get_diagnosis` is already defined)\n",
    "# # def get_diagnosis(mask_path):\n",
    "# #     # Example function logic (already provided in the tutorial)\n",
    "# #     return \"Diagnosis_Info\"  \n",
    "\n",
    "# # Your code here:\n",
    "# mri_df['mask'] = mri_df['mask_path'].apply(lambda x: _______________)\n",
    "\n",
    "# mri_df['mask_path'] = mri_df['mask_path'].apply(lambda x: _______________)\n",
    "\n",
    "# # Check the shape of the DataFrame\n",
    "# print(mri_df.shape)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# mri_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:24:59.979364Z",
     "iopub.status.busy": "2025-04-11T14:24:59.979111Z",
     "iopub.status.idle": "2025-04-11T14:25:25.668794Z",
     "shell.execute_reply": "2025-04-11T14:25:25.667862Z",
     "shell.execute_reply.started": "2025-04-11T14:24:59.979334Z"
    }
   },
   "outputs": [],
   "source": [
    "mri_df['mask'] = mri_df['mask_path'].apply(lambda x: get_diagnosis(x))\n",
    "\n",
    "mri_df['mask_path'] = mri_df['mask_path'].apply(lambda x: str(x))\n",
    "\n",
    "print(mri_df.shape)\n",
    "mri_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:25.670144Z",
     "iopub.status.busy": "2025-04-11T14:25:25.669809Z",
     "iopub.status.idle": "2025-04-11T14:25:25.675480Z",
     "shell.execute_reply": "2025-04-11T14:25:25.674657Z",
     "shell.execute_reply.started": "2025-04-11T14:25:25.670110Z"
    }
   },
   "outputs": [],
   "source": [
    "mri_df.drop(columns=['patient_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:25px\">EDA</span> <a id=2></a> <br>\n",
    "\n",
    "Check Balancing in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:25.676684Z",
     "iopub.status.busy": "2025-04-11T14:25:25.676386Z",
     "iopub.status.idle": "2025-04-11T14:25:25.931747Z",
     "shell.execute_reply": "2025-04-11T14:25:25.930916Z",
     "shell.execute_reply.started": "2025-04-11T14:25:25.676655Z"
    }
   },
   "outputs": [],
   "source": [
    "mri_df['mask'].value_counts().plot(kind='bar',color=['g','r'],\n",
    "                title='Count of Tumour vs No Tumour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:25.932918Z",
     "iopub.status.busy": "2025-04-11T14:25:25.932607Z",
     "iopub.status.idle": "2025-04-11T14:25:25.939341Z",
     "shell.execute_reply": "2025-04-11T14:25:25.938686Z",
     "shell.execute_reply.started": "2025-04-11T14:25:25.932888Z"
    }
   },
   "outputs": [],
   "source": [
    "mri_df['mask'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:25px\">Image Visualization</span> <a id=2.1></a> <br>\n",
    "\n",
    "Visualising the Brain MRI with Tumour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:25.942185Z",
     "iopub.status.busy": "2025-04-11T14:25:25.941954Z",
     "iopub.status.idle": "2025-04-11T14:25:25.956370Z",
     "shell.execute_reply": "2025-04-11T14:25:25.955334Z",
     "shell.execute_reply.started": "2025-04-11T14:25:25.942165Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Quiz: Visualizing Brain MRI Scans and Masks\n",
    "\n",
    "# # Given a DataFrame `mri_df` containing MRI images and corresponding masks,\n",
    "# # the goal is to visualize the original MRI, the mask, and the MRI with the mask overlaid.\n",
    "\n",
    "# # Fill in the missing parts of the code to correctly display MRI images with masks.\n",
    "\n",
    "# # Initialize counters\n",
    "# count = 0\n",
    "# i = 0\n",
    "\n",
    "# # Create a figure with subplots\n",
    "# fig, axs = plt.subplots(3, 3, figsize=(20, 15))\n",
    "\n",
    "# # Iterate through the DataFrame and plot images with masks\n",
    "# for mask in mri_df['mask']:\n",
    "#     if (mask == 1):\n",
    "#         img = io.imread(mri_df.img_path[i])  # Load the MRI image\n",
    "#         print(img.shape)\n",
    "        \n",
    "#         axs[count][0].title.set_text(\"Brain MRI\")\n",
    "#         axs[count][0].imshow(__________)  # Fill in the correct variable\n",
    "        \n",
    "#         mask = io.imread(mri_df.mask_path[i])  # Load the mask\n",
    "#         axs[count][1].title.set_text(\"Mask = \" + str(mri_df['mask'][i]))\n",
    "#         axs[count][1].imshow(__________, cmap='gray')  # Fill in the correct variable\n",
    "        \n",
    "#         # Overlay the mask on the MRI image\n",
    "#         img[mask == 255] = (255, 0, 0)  # Change pixel color at mask positions\n",
    "        \n",
    "#         axs[count][2].title.set_text(\"MRI with Mask = \" + str(mri_df['mask'][i]))\n",
    "#         axs[count][2].imshow(__________)  # Fill in the correct variable\n",
    "        \n",
    "#         count += 1  # Move to the next row\n",
    "#     i += 1  # Move to the next image\n",
    "#     if (count == 3):  # Stop after plotting 3 examples\n",
    "#         break\n",
    "\n",
    "# # Adjust layout\n",
    "# fig.tight_layout()\n",
    "\n",
    "# # What you need to do:\n",
    "# # - Fill in the blanks to ensure images and masks are displayed correctly.\n",
    "# # - Understand how the mask is overlaid on the MRI image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:25.958646Z",
     "iopub.status.busy": "2025-04-11T14:25:25.958247Z",
     "iopub.status.idle": "2025-04-11T14:25:28.336322Z",
     "shell.execute_reply": "2025-04-11T14:25:28.335250Z",
     "shell.execute_reply.started": "2025-04-11T14:25:25.958610Z"
    }
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "i = 0\n",
    "fig,axs = plt.subplots(3,3, figsize=(20,15))\n",
    "for mask in mri_df['mask']:\n",
    "    if (mask==1):\n",
    "        img = io.imread(mri_df.img_path[i])\n",
    "        print(img.shape)\n",
    "        axs[count][0].title.set_text(\"Brain MRI\")\n",
    "        axs[count][0].imshow(img)\n",
    "        \n",
    "        mask = io.imread(mri_df.mask_path[i])\n",
    "        axs[count][1].title.set_text(\"Mask =\" + str(mri_df['mask'][i]))\n",
    "        axs[count][1].imshow(mask, cmap='gray')\n",
    "        \n",
    "        img[mask==255] = (255,0,0)  # change pixel color at the position of mask\n",
    "        axs[count][2].title.set_text(\"MRI with Mask =\" + str(mri_df['mask'][i]))\n",
    "        axs[count][2].imshow(img)\n",
    "        count +=1\n",
    "    i += 1\n",
    "    if (count==3):\n",
    "        break\n",
    "        \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:25px\">Prepare data loaders </span> <a id=3></a> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:28.337557Z",
     "iopub.status.busy": "2025-04-11T14:25:28.337247Z",
     "iopub.status.idle": "2025-04-11T14:25:28.341604Z",
     "shell.execute_reply": "2025-04-11T14:25:28.340672Z",
     "shell.execute_reply.started": "2025-04-11T14:25:28.337535Z"
    }
   },
   "outputs": [],
   "source": [
    "image_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "#     torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "mask_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:22px\">Dataset</span> <a id=1.1.1></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:28.342687Z",
     "iopub.status.busy": "2025-04-11T14:25:28.342468Z",
     "iopub.status.idle": "2025-04-11T14:25:28.355717Z",
     "shell.execute_reply": "2025-04-11T14:25:28.355059Z",
     "shell.execute_reply.started": "2025-04-11T14:25:28.342668Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_data(img, mask):\n",
    "    img = img / 255.\n",
    "    mask = mask / 255.\n",
    "    mask[mask > 0.5] = 1.0\n",
    "    mask[mask <= 0.5] = 0.0\n",
    "    \n",
    "    return (img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:28.356681Z",
     "iopub.status.busy": "2025-04-11T14:25:28.356457Z",
     "iopub.status.idle": "2025-04-11T14:25:28.369742Z",
     "shell.execute_reply": "2025-04-11T14:25:28.369019Z",
     "shell.execute_reply.started": "2025-04-11T14:25:28.356660Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Quiz: Understanding the Custom Dataset Class in PyTorch\n",
    "\n",
    "# # Below is a custom dataset class that loads MRI images and their corresponding masks.\n",
    "# # Your task is to fill in the blanks and answer the quiz questions.\n",
    "\n",
    "\n",
    "# class MyDataset(Dataset):\n",
    "#     def __init__(self, df=mri_df, \n",
    "#                  adjust_data=adjust_data, \n",
    "#                  image_transform=image_transform, \n",
    "#                  mask_transform=mask_transform):\n",
    "#         self.df = df\n",
    "#         self.image_transform = image_transform\n",
    "#         self.mask_transform = mask_transform\n",
    "#         self.adjust_data = adjust_data\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return __________  # Fill in the missing code to return dataset length\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         image_path = self.df.loc[idx, 'img_path']\n",
    "#         mask_path = self.df.loc[idx, 'mask_path']\n",
    "\n",
    "#         # Load the image and mask\n",
    "#         image = cv2.imread(image_path)\n",
    "#         image = cv2.cvtColor(image, __________)  # Convert to RGB\n",
    "\n",
    "#         mask = cv2.imread(mask_path)\n",
    "#         mask = cv2.cvtColor(mask, __________)  # Convert mask to grayscale\n",
    "\n",
    "#         # Apply data adjustments\n",
    "#         image, mask = self.adjust_data(image, mask)\n",
    "\n",
    "#         # Apply transformations if provided\n",
    "#         if self.image_transform:\n",
    "#             image = __________  # Apply image transformation\n",
    "\n",
    "#         if self.mask_transform:\n",
    "#             mask = __________  # Apply mask transformation\n",
    "\n",
    "#         return image, mask\n",
    "\n",
    "# # Quiz Questions:\n",
    "# # 1. What is the purpose of `__len__()` in this class?\n",
    "# # 2. Why do we convert the image from BGR to RGB?\n",
    "# # 3. What will happen if `adjust_data` is not correctly defined?\n",
    "# # 4. What type of transformations could be applied to `image_transform` and `mask_transform`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:28.370695Z",
     "iopub.status.busy": "2025-04-11T14:25:28.370454Z",
     "iopub.status.idle": "2025-04-11T14:25:28.388364Z",
     "shell.execute_reply": "2025-04-11T14:25:28.387584Z",
     "shell.execute_reply.started": "2025-04-11T14:25:28.370676Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df= mri_df, \n",
    "                 adjust_data = adjust_data, \n",
    "                 image_transform=image_transform, mask_transform=mask_transform):\n",
    "        self.df = df\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.adjust_data= adjust_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.df.loc[idx, 'img_path']\n",
    "        mask_path = self.df.loc[idx, 'mask_path']\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path)\n",
    "#         mask =cv2.imread(mask_path, 0)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "#         _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        image, mask = self.adjust_data(image, mask)\n",
    "\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image).float()\n",
    "\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:22px\">Sample</span> <a id=1.1.1></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:28.389390Z",
     "iopub.status.busy": "2025-04-11T14:25:28.389073Z",
     "iopub.status.idle": "2025-04-11T14:25:28.446214Z",
     "shell.execute_reply": "2025-04-11T14:25:28.445585Z",
     "shell.execute_reply.started": "2025-04-11T14:25:28.389359Z"
    }
   },
   "outputs": [],
   "source": [
    "index = 2911\n",
    "data = MyDataset()[index]\n",
    "data[0].shape, data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:28.447259Z",
     "iopub.status.busy": "2025-04-11T14:25:28.446952Z",
     "iopub.status.idle": "2025-04-11T14:25:28.669864Z",
     "shell.execute_reply": "2025-04-11T14:25:28.668859Z",
     "shell.execute_reply.started": "2025-04-11T14:25:28.447222Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(data[0].permute(1, 2, 0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:28.671046Z",
     "iopub.status.busy": "2025-04-11T14:25:28.670797Z",
     "iopub.status.idle": "2025-04-11T14:25:28.854259Z",
     "shell.execute_reply": "2025-04-11T14:25:28.853554Z",
     "shell.execute_reply.started": "2025-04-11T14:25:28.671024Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(data[1].permute(1, 2, 0).squeeze(-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:28.855164Z",
     "iopub.status.busy": "2025-04-11T14:25:28.854961Z",
     "iopub.status.idle": "2025-04-11T14:25:28.862761Z",
     "shell.execute_reply": "2025-04-11T14:25:28.861835Z",
     "shell.execute_reply.started": "2025-04-11T14:25:28.855147Z"
    }
   },
   "outputs": [],
   "source": [
    "np.unique(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:22px\">DataLoader</span> <a id=1.1.1></a> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:28.863749Z",
     "iopub.status.busy": "2025-04-11T14:25:28.863509Z",
     "iopub.status.idle": "2025-04-11T14:25:28.873195Z",
     "shell.execute_reply": "2025-04-11T14:25:28.872572Z",
     "shell.execute_reply.started": "2025-04-11T14:25:28.863729Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Quiz: Understanding Data Loading in PyTorch\n",
    "\n",
    "# # The function below prepares data loaders for training, validation, and testing.\n",
    "# # Your task is to fill in the blanks and answer the quiz questions.\n",
    "\n",
    "# import os\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# def prepare_loaders(df=mri_df,\n",
    "#                     train_num=int(mri_df.shape[0] * 0.6), \n",
    "#                     valid_num=int(mri_df.shape[0] * 0.8), \n",
    "#                     bs=32):\n",
    "    \n",
    "#     train = df[:train_num].reset_index(drop=True)\n",
    "#     valid = df[train_num:valid_num].reset_index(drop=True)    \n",
    "#     test  = df[valid_num:].reset_index(drop=True)\n",
    "\n",
    "#     train_ds = MyDataset(df=__________)  # Fill in the correct dataset\n",
    "#     valid_ds = MyDataset(df=__________)  # Fill in the correct dataset\n",
    "#     test_ds = MyDataset(df=__________)   # Fill in the correct dataset\n",
    "\n",
    "#     train_loader = DataLoader(train_ds, batch_size=bs, num_workers=os.cpu_count(), shuffle=True)\n",
    "#     valid_loader = DataLoader(valid_ds, batch_size=bs, num_workers=os.cpu_count(), shuffle=False)\n",
    "#     test_loader = DataLoader(test_ds, batch_size=4, num_workers=os.cpu_count(), shuffle=True)\n",
    "    \n",
    "#     print(\"DataLoader Completed\")\n",
    "    \n",
    "#     return train_loader, valid_loader, test_loader\n",
    "\n",
    "# # Quiz Questions:\n",
    "# # 1. What percentage of the dataset is used for training, validation, and testing?\n",
    "# # 2. What does `shuffle=True` do in DataLoader?\n",
    "# # 3. Why do we reset the index of the train, validation, and test sets?\n",
    "# # 4. What is the significance of setting `batch_size=4` for the test set?\n",
    "# # 5. How would you modify this function to allow for a different dataset split ratio?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:38.326976Z",
     "iopub.status.busy": "2025-04-11T14:25:38.326671Z",
     "iopub.status.idle": "2025-04-11T14:25:38.332903Z",
     "shell.execute_reply": "2025-04-11T14:25:38.331872Z",
     "shell.execute_reply.started": "2025-04-11T14:25:38.326954Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_loaders(df= mri_df,\n",
    "                    train_num= int(mri_df.shape[0] * .6), \n",
    "                    valid_num= int(mri_df.shape[0] * .8), \n",
    "                    bs = 32):\n",
    "    \n",
    "    train = df[:train_num].reset_index(drop=True)\n",
    "    valid = df[train_num : valid_num].reset_index(drop=True)    \n",
    "    test  = df[valid_num:].reset_index(drop=True)\n",
    "\n",
    "    train_ds = MyDataset(df = train)\n",
    "    valid_ds = MyDataset(df = valid)\n",
    "    test_ds = MyDataset(df = test)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size = bs, num_workers = os.cpu_count(), shuffle = True)\n",
    "    valid_loader = DataLoader(valid_ds, batch_size = bs, num_workers = os.cpu_count(), shuffle = False)\n",
    "    test_loader = DataLoader(test_ds, batch_size = 4, num_workers = os.cpu_count(), shuffle = True)\n",
    "    \n",
    "    print(\"DataLoader Completed\")\n",
    "    \n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:38.703233Z",
     "iopub.status.busy": "2025-04-11T14:25:38.702941Z",
     "iopub.status.idle": "2025-04-11T14:25:38.709975Z",
     "shell.execute_reply": "2025-04-11T14:25:38.709211Z",
     "shell.execute_reply.started": "2025-04-11T14:25:38.703210Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = prepare_loaders(df= mri_df,\n",
    "                                                            train_num= int(mri_df.shape[0] * .65), \n",
    "                                                            valid_num= int(mri_df.shape[0] * .85), \n",
    "                                                            bs = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:50.258256Z",
     "iopub.status.busy": "2025-04-11T14:25:50.257934Z",
     "iopub.status.idle": "2025-04-11T14:25:51.464738Z",
     "shell.execute_reply": "2025-04-11T14:25:51.463743Z",
     "shell.execute_reply.started": "2025-04-11T14:25:50.258223Z"
    }
   },
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))\n",
    "data[0].shape, data[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:blue;background-color:white;font-size:25px\">Build UNet Model Architecture</span> <a id=4></a> <br>\n",
    "\n",
    "<!-- # <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:25px\">UNet Architecture</span> <a id=4.1></a> -->\n",
    "\n",
    "<center><img src= \"https://miro.medium.com/max/1200/1*f7YOaE4TWubwaFF7Z1fzNw.png\" alt =\"UNet\" style='width:800px;'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNet is named after the shape of it's architecture (U - shaped). UNet model is used to solve Image Segmentation problems especially in Medical related problems.\n",
    "\n",
    "The input layer has 572x572x1 dimension in the above architecture. The 1 column dimension specifies the input is b/w image. If the input dimension was 572x572x3 , the input image is rgb coloured image.\n",
    "After the input layer,we can divide this UNet architecture into 4 parts\n",
    "* Encoder Part (Contracting path)\n",
    "* Upsampling2D\n",
    "* Decoder part (Expanding Path)\n",
    "* Skip Connection (Residual connection)\n",
    "\n",
    "\n",
    "Briefly into the Details of these parts: <br>\n",
    "**Encoder Part**\n",
    "The initial half of the U-shaped architecture is the Contracting path(Encoder part). As the name Contracting path denotes, the dimension of the input image keeps reducing as it passes through 2 Conv2D 3X3 kernel size, ReLU activation and filters=64 followed by Maxpool2D layer (reduces size divided by 2). Now again 2 - Conv2D layers (128 filters) and 1 Maxpooling2D , 2 - Conv2D layers (256 filters) and 1 Maxpooling2D completely contracts the output dimension through layers. This is similar to the Zoom in of the image through each layer. \n",
    "\n",
    "**Upsampling2D**\n",
    "The Upsampling2D layer upsamples the layer output dimension by duplicating the row values twice.The concatenation of the upsampling2D and contracting path happens here leading into the Expanding path.\n",
    "The Upsampling layer is present after 2 conv2D layers in Decoder part, similar to presence of  Maxpooling as in Encoder part.\n",
    "\n",
    "**Decoder Path**\n",
    "The second half of the U-shaped architecture is the Expanding path(Decoder part). As the name Expanding path denotes, the dimension of the image keeps expanding as it passes through 2 Conv2D 3X3 kernel size, ReLU activation and filters=512 followed by Upsampling2D layer (duplicates size divided by 2). Now again 2 - Conv2D layers (256 filters) and 1 Upsampling2D ,2 - Conv2D layers (128 filters) and 1 Upsampling2D, 2 - Conv2D layers (64 filters) completely expands the output dimension through layers. This is similar to the Zoom in of the image through each layer. \n",
    "\n",
    "**Skip Connection (Residual connection)**\n",
    "The Skip Connection (Residual connection) alias the identity mapping is present after each of the 2 Conv2D layers in Encoder to the corresponding same shaped dimension layer in the Decoder part . In the above architecture the copy and crop does residual connection task.The Concatenate layer does the work of adding those two layers. This skip connection doesnot harm the model in any way even in worst case but definitely benificial to the output in the model.\n",
    "\n",
    "Finally the decoder part ends with the Output Segmentation map with filters 2. This layer is again passed through a Conv2D with Sigmoid activation and filters 1. The output classifies each pixel if tumour is present or not in it. \n",
    "\n",
    "**UNet Model build**\n",
    "Here in the model built below, after each of second Convolutional layer,Batch Normalization layer with axis=3 is added to prevent \"internal covariance shift\" , the Activation layer \"relu\" is added here instead of that second Convolutional layer.\n",
    "\n",
    "### Reference : [Lee etal](https://doi.org/10.1016/j.dib.2024.111159); [UNet](https://github.com/zhixuhao/unet); [Thomas Brox](https://arxiv.org/pdf/1505.04597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:53.393677Z",
     "iopub.status.busy": "2025-04-11T14:25:53.393348Z",
     "iopub.status.idle": "2025-04-11T14:25:53.448715Z",
     "shell.execute_reply": "2025-04-11T14:25:53.447906Z",
     "shell.execute_reply.started": "2025-04-11T14:25:53.393654Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:53.660281Z",
     "iopub.status.busy": "2025-04-11T14:25:53.659953Z",
     "iopub.status.idle": "2025-04-11T14:25:53.666007Z",
     "shell.execute_reply": "2025-04-11T14:25:53.664976Z",
     "shell.execute_reply.started": "2025-04-11T14:25:53.660250Z"
    }
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, inputs = 3, middles = 64, outs = 64):\n",
    "        super().__init__()\n",
    "        #self.device = device\n",
    "        #self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(inputs, middles, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(middles, outs, 3, 1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm2d(outs)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.bn(self.conv2(x)))\n",
    "        # e1 = x\n",
    "        # x = self.pool(x)\n",
    "        \n",
    "        return self.pool(x), x\n",
    "        # self.pool(x): [bs, out, h*.5, w*.5]\n",
    "        # x: [bs, out, h, w]    \n",
    "    \n",
    "        # return x, e1\n",
    "        # x: [bs, out, h*.5, w*.5]\n",
    "        # e1: [bs, out, h, w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:53.937038Z",
     "iopub.status.busy": "2025-04-11T14:25:53.936751Z",
     "iopub.status.idle": "2025-04-11T14:25:53.940983Z",
     "shell.execute_reply": "2025-04-11T14:25:53.940225Z",
     "shell.execute_reply.started": "2025-04-11T14:25:53.937015Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Quiz: Understanding U-Net Architecture\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# # Below is the U-Net model, which is widely used for image segmentation tasks.\n",
    "# # Your task is to answer the quiz questions and analyze the architecture.\n",
    "\n",
    "# class UNet(nn.Module):\n",
    "#     def __init__(self,):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.en1 = Block(3, 64, 64)\n",
    "#         self.en2 = Block(64, 128, 128)\n",
    "#         self.en3 = Block(128, 256, 256)\n",
    "#         self.en4 = Block(256, 512, 512)\n",
    "#         self.en5 = Block(512, 1024, 512)\n",
    "        \n",
    "#         self.upsample4 = nn.ConvTranspose2d(512, 512, 2, stride=2)\n",
    "#         self.de4 = Block(1024, 512, 256)\n",
    "        \n",
    "#         self.upsample3 = nn.ConvTranspose2d(256, 256, 2, stride=2)\n",
    "#         self.de3 = Block(512, 256, 128)\n",
    "        \n",
    "#         self.upsample2 = nn.ConvTranspose2d(128, 128, 2, stride=2)\n",
    "#         self.de2 = Block(256, 128, 64)\n",
    "        \n",
    "#         self.upsample1 = nn.ConvTranspose2d(64, 64, 2, stride=2)\n",
    "#         self.de1 = Block(128, 64, 64)\n",
    "        \n",
    "#         self.conv_last = nn.Conv2d(64, 1, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x, e1 = self.en1(x)\n",
    "#         x, e2 = self.en2(x)\n",
    "#         x, e3 = self.en3(x)\n",
    "#         x, e4 = self.en4(x)\n",
    "#         _, x = self.en5(x)\n",
    "\n",
    "#         x = self.upsample4(x)\n",
    "#         x = torch.cat([x, e4], dim=1)\n",
    "#         _, x = self.de4(x)\n",
    "\n",
    "#         x = self.upsample3(x)\n",
    "#         x = torch.cat([x, e3], dim=1)\n",
    "#         _, x = self.de3(x)\n",
    "\n",
    "#         x = self.upsample2(x)\n",
    "#         x = torch.cat([x, e2], dim=1)\n",
    "#         _, x = self.de2(x)\n",
    "\n",
    "#         x = self.upsample1(x)\n",
    "#         x = torch.cat([x, e1], dim=1)\n",
    "#         _, x = self.de1(x)\n",
    "\n",
    "#         x = self.conv_last(x)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "# # Instantiate the model and test it\n",
    "# unet_model = UNet()\n",
    "# sample_input = torch.randn(1, 3, 256, 256)  # Batch size 1, 3 channels, 256x256 image\n",
    "# output = unet_model(sample_input)\n",
    "\n",
    "# # Quiz Questions:\n",
    "# # 1. What is the purpose of the encoder (`en1` to `en5`) in the U-Net architecture?\n",
    "# # 2. Why do we use `ConvTranspose2d` layers in the decoder?\n",
    "# # 3. What does the `torch.cat([x, eX], dim=1)` operation achieve?\n",
    "# # 4. How does the output tensor shape (1,1,256,256) relate to the input?\n",
    "# # 5. What would happen if we removed the skip connections in the model?\n",
    "\n",
    "# print(f\"Output Shape: {output.shape}\")  # Should be (1, 1, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:54.270522Z",
     "iopub.status.busy": "2025-04-11T14:25:54.270189Z",
     "iopub.status.idle": "2025-04-11T14:25:54.279070Z",
     "shell.execute_reply": "2025-04-11T14:25:54.278209Z",
     "shell.execute_reply.started": "2025-04-11T14:25:54.270497Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# Tencho's Model\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        #self.device = device\n",
    "        #self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.en1 = Block(3, 64, 64)\n",
    "        self.en2 = Block(64, 128, 128)\n",
    "        self.en3 = Block(128, 256, 256)\n",
    "        self.en4 = Block(256, 512, 512)\n",
    "        self.en5 = Block(512, 1024, 512)\n",
    "        \n",
    "        self.upsample4 = nn.ConvTranspose2d(512, 512, 2, stride = 2)\n",
    "        self.de4 = Block(1024, 512, 256)\n",
    "        \n",
    "        self.upsample3 = nn.ConvTranspose2d(256, 256, 2, stride = 2)\n",
    "        self.de3 = Block(512, 256, 128)\n",
    "        \n",
    "        self.upsample2 = nn.ConvTranspose2d(128, 128, 2, stride = 2)\n",
    "        self.de2 = Block(256, 128, 64)\n",
    "        \n",
    "        self.upsample1 = nn.ConvTranspose2d(64, 64, 2, stride = 2)\n",
    "        self.de1 = Block(128, 64, 64)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, 1, kernel_size=1, stride = 1, padding = 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [bs, 3, 256, 256]\n",
    "        \n",
    "        x, e1 = self.en1(x)\n",
    "        # x: [bs, 64, 128, 128]\n",
    "        # e1: [bs, 64, 256, 256]\n",
    "        \n",
    "        x, e2 = self.en2(x)\n",
    "        # x: [bs, 128, 64, 64]\n",
    "        # e2: [bs, 128, 128, 128]\n",
    "        \n",
    "        x, e3 = self.en3(x)\n",
    "        # x: [bs, 256, 32, 32]\n",
    "        # e3: [bs, 256, 64, 64]\n",
    "        \n",
    "        x, e4 = self.en4(x)\n",
    "        # x: [bs, 512, 16, 16]\n",
    "        # e4: [bs, 512, 32, 32]\n",
    "        \n",
    "        _, x = self.en5(x)\n",
    "        # x: [bs, 512, 16, 16]\n",
    "        \n",
    "        x = self.upsample4(x)\n",
    "        # x: [bs, 512, 32, 32]\n",
    "        x = torch.cat([x, e4], dim=1)\n",
    "        # x: [bs, 1024, 32, 32]\n",
    "        _,  x = self.de4(x)\n",
    "        # x: [bs, 256, 32, 32]\n",
    "        \n",
    "        x = self.upsample3(x)\n",
    "        # x: [bs, 256, 64, 64]\n",
    "        x = torch.cat([x, e3], dim=1)\n",
    "        # x: [bs, 512, 64, 64]\n",
    "        _, x = self.de3(x)\n",
    "        # x: [bs, 128, 64, 64]\n",
    "        \n",
    "        x = self.upsample2(x)\n",
    "        # x: [bs, 128, 128, 128]\n",
    "        x = torch.cat([x, e2], dim=1)\n",
    "        # x: [bs, 256, 128, 128]\n",
    "        _, x = self.de2(x)\n",
    "        # x: [bs, 64, 128, 128]\n",
    "        \n",
    "        x = self.upsample1(x)\n",
    "        # x: [bs, 64, 256, 256]\n",
    "        x = torch.cat([x, e1], dim=1)\n",
    "        # x: [bs, 128, 256,256, 256\n",
    "        _, x = self.de1(x)\n",
    "        # x: [bs, 64, 256, 256]\n",
    "        \n",
    "        x = self.conv_last(x)\n",
    "        # x: [bs, 1, 256, 256]\n",
    "        \n",
    "        # x = x.squeeze(1)         \n",
    "        return x\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:54.590726Z",
     "iopub.status.busy": "2025-04-11T14:25:54.590408Z",
     "iopub.status.idle": "2025-04-11T14:25:54.997783Z",
     "shell.execute_reply": "2025-04-11T14:25:54.996991Z",
     "shell.execute_reply.started": "2025-04-11T14:25:54.590703Z"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:25px\">Loss_fxn & Optimizer</span> <a id=5></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:55.312747Z",
     "iopub.status.busy": "2025-04-11T14:25:55.312365Z",
     "iopub.status.idle": "2025-04-11T14:25:55.318659Z",
     "shell.execute_reply": "2025-04-11T14:25:55.317758Z",
     "shell.execute_reply.started": "2025-04-11T14:25:55.312716Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss_fn = nn.BCELoss().to(device)\n",
    "loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:55.771579Z",
     "iopub.status.busy": "2025-04-11T14:25:55.771146Z",
     "iopub.status.idle": "2025-04-11T14:25:55.776263Z",
     "shell.execute_reply": "2025-04-11T14:25:55.775169Z",
     "shell.execute_reply.started": "2025-04-11T14:25:55.771545Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scheduler\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max = 200,eta_min = 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:25px\">Train one epoch</span> <a id=5></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:25:56.892456Z",
     "iopub.status.busy": "2025-04-11T14:25:56.892095Z",
     "iopub.status.idle": "2025-04-11T14:25:56.902680Z",
     "shell.execute_reply": "2025-04-11T14:25:56.901818Z",
     "shell.execute_reply.started": "2025-04-11T14:25:56.892426Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model = model, \n",
    "                    dataloader = train_loader, \n",
    "                    loss_fn = loss_fn, \n",
    "                    optimizer = optimizer,\n",
    "                    scheduler = None,\n",
    "                    device = device, \n",
    "                    epoch = 1):\n",
    "    model.train() \n",
    "    train_loss, dataset_size = 0,  0\n",
    "    \n",
    "    bar = tqdm(dataloader, total = len(dataloader))\n",
    "    tp_l, fp_l, fn_l, tn_l = [], [], [], []\n",
    "    \n",
    "    for data in bar:\n",
    "        x = data[0].to(device)     \n",
    "        y_true = data[1].to(device) \n",
    "        y_pred = model(x)          \n",
    "        \n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "        \n",
    "        pred_mask = (y_pred > 0.5).float()\n",
    "        btp, bfp, bfn, btn = smp.metrics.get_stats(pred_mask.long(), y_true.long(), mode=\"binary\")\n",
    "\n",
    "        # \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # train_epoch_loss\n",
    "        # why? tqdm \n",
    "        bs = x.shape[0]\n",
    "        dataset_size += bs\n",
    "        train_loss += (loss.item() * bs)\n",
    "        train_epoch_loss = train_loss / dataset_size\n",
    "        \n",
    "        tp_l.append(btp)\n",
    "        fp_l.append(bfp)\n",
    "        fn_l.append(bfn)\n",
    "        tn_l.append(btn)\n",
    "        \n",
    "        tp = torch.cat(tp_l)\n",
    "        fp = torch.cat(fp_l)\n",
    "        fn = torch.cat(fn_l)\n",
    "        tn = torch.cat(tn_l)\n",
    "        \n",
    "        recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro\")\n",
    "        precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")\n",
    "        \n",
    "        f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "        accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n",
    "        \n",
    "        # per image IoU means that we first calculate IoU score for each image \n",
    "        # and then compute mean over these scores\n",
    "        per_image_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
    "        \n",
    "        # dataset IoU means that we aggregate intersection and union over whole dataset\n",
    "        # and then compute IoU score. The difference between dataset_iou and per_image_iou scores\n",
    "        # in this particular case will not be much, however for dataset \n",
    "        # with \"empty\" images (images without target class) a large gap could be observed. \n",
    "        # Empty images influence a lot on per_image_iou and much less on dataset_iou.\n",
    "        dataset_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "\n",
    "        bar.set_description(f\"EP:{epoch} | TL:{train_epoch_loss:.3e} | ACC: {accuracy:.2f} | F1: {f1_score:.3f} \")\n",
    "        \n",
    "    metrics =  dict()\n",
    "    \n",
    "    metrics['f1_score'] = f1_score.detach().cpu().item()\n",
    "    metrics['accuracy'] = accuracy.detach().cpu().item()\n",
    "    \n",
    "    metrics['recall'] = recall.detach().cpu().item()\n",
    "    metrics['precision'] = precision.detach().cpu().item()\n",
    "    \n",
    "    metrics['dataset_iou'] = dataset_iou.detach().cpu().item()\n",
    "    metrics['per_iou'] = per_image_iou.detach().cpu().item()\n",
    "    \n",
    "    metrics['loss'] = train_epoch_loss\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:26:00.967087Z",
     "iopub.status.busy": "2025-04-11T14:26:00.966752Z",
     "iopub.status.idle": "2025-04-11T14:26:00.970722Z",
     "shell.execute_reply": "2025-04-11T14:26:00.969754Z",
     "shell.execute_reply.started": "2025-04-11T14:26:00.967059Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Quiz: Understanding the Training Function in Deep Learning\n",
    "\n",
    "# # The function `train_one_epoch` is responsible for training the model for one epoch.\n",
    "# # It updates the model's parameters using backpropagation, calculates loss, and evaluates performance metrics.\n",
    "\n",
    "# # Quiz Questions:\n",
    "# # 1. What does `model.train()` do at the beginning of each epoch?\n",
    "# # 2. Why do we use `optimizer.zero_grad()` before calling `loss.backward()`?\n",
    "# # 3. What is the purpose of the `scheduler` in this function?\n",
    "# # 4. What do `tp`, `fp`, `fn`, and `tn` stand for in the segmentation context?\n",
    "# # 5. What is the difference between `per_image_iou` and `dataset_iou`?\n",
    "# # 6. How does `bar.set_description(...)` help in tracking training progress?\n",
    "\n",
    "# print(\"Answer the above questions to test your understanding of the training function!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:25px\">Valid one epoch</span> <a id=5.1></a> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:26:14.169639Z",
     "iopub.status.busy": "2025-04-11T14:26:14.169330Z",
     "iopub.status.idle": "2025-04-11T14:26:14.179118Z",
     "shell.execute_reply": "2025-04-11T14:26:14.177919Z",
     "shell.execute_reply.started": "2025-04-11T14:26:14.169616Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model = model, \n",
    "                    dataloader = valid_loader, \n",
    "                    loss_fn = loss_fn,\n",
    "                    device = device, \n",
    "                    epoch = 0):\n",
    "    model.eval() \n",
    "    valid_loss, dataset_size = 0,  0\n",
    "    bar = tqdm(dataloader, total = len(dataloader))\n",
    "    tp_l, fp_l, fn_l, tn_l = [], [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in bar:\n",
    "            x = data[0].to(device)     \n",
    "            y_true = data[1].to(device) \n",
    "            y_pred = model(x)        \n",
    "            \n",
    "            loss = loss_fn(y_pred, y_true)\n",
    "            \n",
    "            pred_mask = (y_pred > 0.5).float()\n",
    "            btp, bfp, bfn, btn = smp.metrics.get_stats(pred_mask.long(), y_true.long(), mode=\"binary\")\n",
    "\n",
    "            tp_l.append(btp)\n",
    "            fp_l.append(bfp)\n",
    "            fn_l.append(bfn)\n",
    "            tn_l.append(btn)\n",
    "\n",
    "            tp = torch.cat(tp_l)\n",
    "            fp = torch.cat(fp_l)\n",
    "            fn = torch.cat(fn_l)\n",
    "            tn = torch.cat(tn_l)\n",
    "\n",
    "            recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro\")\n",
    "            precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")\n",
    "\n",
    "            f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "            accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n",
    "\n",
    "            # per image IoU means that we first calculate IoU score for each image \n",
    "            # and then compute mean over these scores\n",
    "            per_image_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
    "\n",
    "            # dataset IoU means that we aggregate intersection and union over whole dataset\n",
    "            # and then compute IoU score. The difference between dataset_iou and per_image_iou scores\n",
    "            # in this particular case will not be much, however for dataset \n",
    "            # with \"empty\" images (images without target class) a large gap could be observed. \n",
    "            # Empty images influence a lot on per_image_iou and much less on dataset_iou.\n",
    "            dataset_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "\n",
    "            # valid_epoch_loss \n",
    "            bs = x.shape[0]\n",
    "            dataset_size += bs\n",
    "            valid_loss += (loss.item() * bs)\n",
    "            valid_epoch_loss = valid_loss / dataset_size\n",
    "\n",
    "            bar.set_description(f\"EP:{epoch} | VL:{valid_epoch_loss:.3e} | ACC: {accuracy:.2f} | F1: {f1_score:.3f} \")\n",
    "\n",
    "    metrics =  dict()\n",
    "    \n",
    "    metrics['f1_score'] = f1_score.detach().cpu().item()\n",
    "    metrics['accuracy'] = accuracy.detach().cpu().item()\n",
    "    \n",
    "    metrics['recall'] = recall.detach().cpu().item()\n",
    "    metrics['precision'] = precision.detach().cpu().item()\n",
    "    \n",
    "    metrics['dataset_iou'] = dataset_iou.detach().cpu().item()\n",
    "    metrics['per_iou'] = per_image_iou.detach().cpu().item()\n",
    "    \n",
    "    metrics['loss'] = valid_epoch_loss\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:26:17.078982Z",
     "iopub.status.busy": "2025-04-11T14:26:17.078671Z",
     "iopub.status.idle": "2025-04-11T14:26:17.082474Z",
     "shell.execute_reply": "2025-04-11T14:26:17.081622Z",
     "shell.execute_reply.started": "2025-04-11T14:26:17.078959Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Quiz: Understanding the Validation Function in Deep Learning\n",
    "\n",
    "# # The function `valid_one_epoch` is responsible for evaluating the model on the validation set.\n",
    "# # It computes loss and metrics without updating the modelâ€™s parameters.\n",
    "\n",
    "# # Quiz Questions:\n",
    "# # 1. What is the purpose of `@torch.no_grad()` at the beginning of this function?\n",
    "# # 2. Why do we use `model.eval()` during validation?\n",
    "# # 3. How does `loss_fn(y_pred, y_true)` contribute to model evaluation?\n",
    "# # 4. What do `tp`, `fp`, `fn`, and `tn` stand for, and why are they important in segmentation tasks?\n",
    "# # 5. Why is it necessary to compute both `per_image_iou` and `dataset_iou`?\n",
    "# # 6. What does the line `valid_epoch_loss = valid_loss / dataset_size` represent?\n",
    "# # 7. How does `bar.set_description(...)` improve the validation tracking process?\n",
    "\n",
    "# print(\"Answer the above questions to test your understanding of the validation function!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:25px\">Model training</span> <a id=5.1></a> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:26:22.622210Z",
     "iopub.status.busy": "2025-04-11T14:26:22.621907Z",
     "iopub.status.idle": "2025-04-11T14:26:22.635262Z",
     "shell.execute_reply": "2025-04-11T14:26:22.634116Z",
     "shell.execute_reply.started": "2025-04-11T14:26:22.622187Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def run_training(model = model, \n",
    "                 loss_fn = loss_fn, \n",
    "                 train_loader = train_loader,\n",
    "                 valid_loader = valid_loader,\n",
    "                 optimizer = optimizer, \n",
    "                 device = device, \n",
    "                 n_epochs=100, \n",
    "                 early_stop = 20,\n",
    "                 scheduler = None):\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"INFO: GPU - {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    lowest_epoch, lowest_loss = np.inf, np.inf\n",
    "    \n",
    "    train_history, valid_history = [],  []\n",
    "    train_recalls, valid_recalls = [],  []\n",
    "    \n",
    "    train_pres, valid_pres = [],  []\n",
    "    train_accs, valid_accs = [],  []\n",
    "    \n",
    "    train_f1s, valid_f1s = [],  []\n",
    "    \n",
    "    train_per_ious, valid_per_ious = [], []\n",
    "    train_dataset_ious, valid_dataset_ious = [], []\n",
    "    \n",
    "    print_iter = 5\n",
    "\n",
    "    best_score = 0\n",
    "    best_model = \"None\"\n",
    "\n",
    "    for epoch in range(0, n_epochs):\n",
    "        gc.collect()\n",
    "\n",
    "        train_metrics = train_one_epoch(model= model,\n",
    "                                       dataloader = train_loader,\n",
    "                                       optimizer = optimizer,\n",
    "                                       scheduler = scheduler,\n",
    "                                       device = device,\n",
    "                                       epoch = epoch + 1\n",
    "                                       )\n",
    "        \n",
    "        valid_metrics = valid_one_epoch(model,\n",
    "                                       dataloader = valid_loader,\n",
    "                                       device = device,\n",
    "                                       epoch = epoch + 1)\n",
    "        \n",
    "        # \n",
    "        train_history += [train_metrics['loss']]\n",
    "        valid_history += [valid_metrics['loss']]\n",
    "        \n",
    "        train_recalls += [train_metrics['recall']]\n",
    "        valid_recalls += [valid_metrics['recall']]\n",
    "        \n",
    "        train_pres += [train_metrics['precision']]\n",
    "        valid_pres += [valid_metrics['precision']]\n",
    "        \n",
    "        train_accs += [train_metrics['accuracy']]\n",
    "        valid_accs += [valid_metrics['accuracy']]\n",
    "        \n",
    "        train_f1s += [train_metrics['f1_score']]\n",
    "        valid_f1s += [valid_metrics['f1_score']]\n",
    "        \n",
    "        train_per_ious += [train_metrics['per_iou']]\n",
    "        valid_per_ious += [valid_metrics['per_iou']]\n",
    "        \n",
    "        train_dataset_ious += [train_metrics['dataset_iou']]\n",
    "        valid_dataset_ious += [valid_metrics['dataset_iou']]\n",
    "        \n",
    "        \n",
    "        print()\n",
    "        if (epoch + 1) % print_iter == 0:\n",
    "            print(f\"Epoch:{epoch + 1}|TL:{train_metrics['loss']:.3e}|VL:{valid_metrics['loss']:.3e}|F1:{valid_metrics['f1_score']:.4f}|Dataset IOU:{valid_metrics['dataset_iou']:.4f}|Per Img IOU:{valid_metrics['per_iou']:.4f}|\")\n",
    "            print()\n",
    "            \n",
    "        if best_score < valid_metrics['f1_score']:\n",
    "            print(f\"Validation F1 Improved({best_score:.2f}) --> ({ valid_metrics['f1_score']:.2f})\")\n",
    "            best_model = model\n",
    "            best_score = valid_metrics['f1_score']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            PATH2 =  f\"model_f1.bin\"\n",
    "            torch.save(model.state_dict(), PATH2)\n",
    "            print(f\"Better_F1_Model Saved\")\n",
    "            print()\n",
    "\n",
    "        if valid_metrics['loss']< lowest_loss:\n",
    "            print(f\"Validation Loss Improved({lowest_loss:.4e}) --> ({ valid_metrics['loss']:.4e})\")\n",
    "            lowest_loss = valid_metrics['loss']\n",
    "            lowest_epoch = epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"model.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            print(f\"Better Loss Model Saved\")\n",
    "            print()\n",
    "        else:\n",
    "            if early_stop > 0 and lowest_epoch + early_stop < epoch + 1:\n",
    "                print(\"Stopping... no improvement!\") #\n",
    "                break\n",
    "                \n",
    "    print()\n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Loss: %.4e at %d th Epoch\" % (lowest_loss, lowest_epoch))\n",
    "\n",
    "    # load best model weights\n",
    "    # model.load_state_dict(best_model_wts)\n",
    "    model.load_state_dict(torch.load('./model_f1.bin'))\n",
    "\n",
    "    result = dict()\n",
    "    result[\"Train Loss\"] = train_history\n",
    "    result[\"Valid Loss\"] = valid_history\n",
    "    \n",
    "    result[\"Train Recall\"] = train_recalls\n",
    "    result[\"Valid Recall\"] = valid_recalls\n",
    "    \n",
    "    result[\"Train Precision\"] = train_pres\n",
    "    result[\"Valid Precision\"] = valid_pres\n",
    "    \n",
    "    result[\"Train Accuracy\"] = train_accs\n",
    "    result[\"Valid Accuracy\"] = valid_accs\n",
    "    \n",
    "    result[\"Train F1 Score\"] = train_f1s\n",
    "    result[\"Valid F1 Score\"] = valid_f1s\n",
    "    \n",
    "    result[\"Train per Image IOU\"] = train_per_ious\n",
    "    result[\"Valid per Image IOU\"] = valid_per_ious\n",
    "    \n",
    "    result[\"Train Dataset IOU\"] = train_dataset_ious\n",
    "    result[\"Valid Dataset IOU\"] = valid_dataset_ious\n",
    "    \n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:25px\">Train Execution</span> <a id=5.1></a> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T14:28:39.927934Z",
     "iopub.status.busy": "2025-04-11T14:28:39.927572Z",
     "iopub.status.idle": "2025-04-11T15:22:01.946992Z",
     "shell.execute_reply": "2025-04-11T15:22:01.945912Z",
     "shell.execute_reply.started": "2025-04-11T14:28:39.927911Z"
    }
   },
   "outputs": [],
   "source": [
    "model, result = run_training(model = model, \n",
    "                             loss_fn = loss_fn, \n",
    "                             optimizer = optimizer, \n",
    "                             device = device, \n",
    "                             scheduler = scheduler,\n",
    "                             n_epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:25px\">Visualization</span> <a id=5.3></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:11.814615Z",
     "iopub.status.busy": "2025-04-11T15:22:11.814372Z",
     "iopub.status.idle": "2025-04-11T15:22:12.072999Z",
     "shell.execute_reply": "2025-04-11T15:22:12.072157Z",
     "shell.execute_reply.started": "2025-04-11T15:22:11.814591Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Train/Valid Loss History\n",
    "plot_from = 0\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Train/Valid Loss History\", fontsize = 20)\n",
    "plt.plot(\n",
    "    range(0, len(result['Train Loss'][plot_from:])), \n",
    "    result['Train Loss'][plot_from:], \n",
    "    label = 'Train Loss'\n",
    "    )\n",
    "\n",
    "plt.plot(\n",
    "    range(0, len(result['Valid Loss'][plot_from:])), \n",
    "    result['Valid Loss'][plot_from:], \n",
    "    label = 'Valid Loss'\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "# plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:02.234086Z",
     "iopub.status.busy": "2025-04-11T15:22:02.233869Z",
     "iopub.status.idle": "2025-04-11T15:22:02.528680Z",
     "shell.execute_reply": "2025-04-11T15:22:02.527820Z",
     "shell.execute_reply.started": "2025-04-11T15:22:02.234067Z"
    }
   },
   "outputs": [],
   "source": [
    "## Train/Valid Accuracy History\n",
    "plot_from = 0\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Train/Valid Accuracy History\", fontsize = 20)\n",
    "plt.plot(\n",
    "    range(0, len(result['Train Accuracy'][plot_from:])), \n",
    "    result['Train Accuracy'][plot_from:], \n",
    "    label = 'Train Accuracy'\n",
    "    )\n",
    "\n",
    "plt.plot(\n",
    "    range(0, len(result['Valid Accuracy'][plot_from:])), \n",
    "    result['Valid Accuracy'][plot_from:], \n",
    "    label = 'Valid Accuracy'\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "# plt.yscale('log')\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:02.530144Z",
     "iopub.status.busy": "2025-04-11T15:22:02.529891Z",
     "iopub.status.idle": "2025-04-11T15:22:02.818350Z",
     "shell.execute_reply": "2025-04-11T15:22:02.817588Z",
     "shell.execute_reply.started": "2025-04-11T15:22:02.530123Z"
    }
   },
   "outputs": [],
   "source": [
    "## Train/Valid Recall History\n",
    "plot_from = 0\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Train/Valid Recall History\", fontsize = 20)\n",
    "plt.plot(\n",
    "    range(0, len(result['Train Recall'][plot_from:])), \n",
    "    result['Train Recall'][plot_from:], \n",
    "    label = 'Train Recall'\n",
    "    )\n",
    "\n",
    "plt.plot(\n",
    "    range(0, len(result['Valid Recall'][plot_from:])), \n",
    "    result['Valid Recall'][plot_from:], \n",
    "    label = 'Valid Recall'\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "# plt.yscale('log')\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:02.819416Z",
     "iopub.status.busy": "2025-04-11T15:22:02.819151Z",
     "iopub.status.idle": "2025-04-11T15:22:03.125544Z",
     "shell.execute_reply": "2025-04-11T15:22:03.124535Z",
     "shell.execute_reply.started": "2025-04-11T15:22:02.819394Z"
    }
   },
   "outputs": [],
   "source": [
    "## Train/Valid Precision History\n",
    "plot_from = 0\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Train/Valid Precision History\", fontsize = 20)\n",
    "plt.plot(\n",
    "    range(0, len(result['Train Precision'][plot_from:])), \n",
    "    result['Train Precision'][plot_from:], \n",
    "    label = 'Train Precision'\n",
    "    )\n",
    "\n",
    "plt.plot(\n",
    "    range(0, len(result['Valid Precision'][plot_from:])), \n",
    "    result['Valid Precision'][plot_from:], \n",
    "    label = 'Valid Precision'\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "# plt.yscale('log')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:03.126955Z",
     "iopub.status.busy": "2025-04-11T15:22:03.126620Z",
     "iopub.status.idle": "2025-04-11T15:22:03.412824Z",
     "shell.execute_reply": "2025-04-11T15:22:03.411908Z",
     "shell.execute_reply.started": "2025-04-11T15:22:03.126920Z"
    }
   },
   "outputs": [],
   "source": [
    "## Train/Valid F1 History\n",
    "plot_from = 0\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Train/Valid F1 Score History\", fontsize = 20)\n",
    "plt.plot(\n",
    "    range(0, len(result['Train F1 Score'][plot_from:])), \n",
    "    result['Train F1 Score'][plot_from:], \n",
    "    label = 'Train F1 Score'\n",
    "    )\n",
    "\n",
    "plt.plot(\n",
    "    range(0, len(result['Valid F1 Score'][plot_from:])), \n",
    "    result['Valid F1 Score'][plot_from:], \n",
    "    label = 'Valid F1 Score'\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "# plt.yscale('log')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:03.413977Z",
     "iopub.status.busy": "2025-04-11T15:22:03.413696Z",
     "iopub.status.idle": "2025-04-11T15:22:03.704024Z",
     "shell.execute_reply": "2025-04-11T15:22:03.703136Z",
     "shell.execute_reply.started": "2025-04-11T15:22:03.413956Z"
    }
   },
   "outputs": [],
   "source": [
    "## Train/Valid Per Image IOU History\n",
    "plot_from = 0\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Train/Valid per Image IOU History\", fontsize = 20)\n",
    "plt.plot(\n",
    "    range(0, len(result['Train per Image IOU'][plot_from:])), \n",
    "    result['Train per Image IOU'][plot_from:], \n",
    "    label = 'Train per Image IOU'\n",
    "    )\n",
    "\n",
    "plt.plot(\n",
    "    range(0, len(result['Valid per Image IOU'][plot_from:])), \n",
    "    result['Valid per Image IOU'][plot_from:], \n",
    "    label = 'Valid per Image IOU'\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "# plt.yscale('log')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:03.706480Z",
     "iopub.status.busy": "2025-04-11T15:22:03.706226Z",
     "iopub.status.idle": "2025-04-11T15:22:04.000343Z",
     "shell.execute_reply": "2025-04-11T15:22:03.999534Z",
     "shell.execute_reply.started": "2025-04-11T15:22:03.706452Z"
    }
   },
   "outputs": [],
   "source": [
    "## Train/Valid Dataset IOU History\n",
    "plot_from = 0\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Train/Valid Dataset IOU History\", fontsize = 20)\n",
    "plt.plot(\n",
    "    range(0, len(result['Train Dataset IOU'][plot_from:])), \n",
    "    result['Train Dataset IOU'][plot_from:], \n",
    "    label = 'Train Dataset IOU'\n",
    "    )\n",
    "\n",
    "plt.plot(\n",
    "    range(0, len(result['Valid Dataset IOU'][plot_from:])), \n",
    "    result['Valid Dataset IOU'][plot_from:], \n",
    "    label = 'Valid Dataset IOU'\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "# plt.yscale('log')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"list-group-item list-group-item-action active\" style=\"color:blue;background-color:white;font-size:25px\">Model Evaluation</span> <a id=6></a>\n",
    "\n",
    "Evaluation metrics are listed below <br>\n",
    "Fq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:04.002057Z",
     "iopub.status.busy": "2025-04-11T15:22:04.001837Z",
     "iopub.status.idle": "2025-04-11T15:22:04.079782Z",
     "shell.execute_reply": "2025-04-11T15:22:04.079018Z",
     "shell.execute_reply.started": "2025-04-11T15:22:04.002037Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('/kaggle/working/model.bin'))\n",
    "model.load_state_dict(torch.load('/kaggle/working/model_f1.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:04.080679Z",
     "iopub.status.busy": "2025-04-11T15:22:04.080467Z",
     "iopub.status.idle": "2025-04-11T15:22:05.223851Z",
     "shell.execute_reply": "2025-04-11T15:22:05.222854Z",
     "shell.execute_reply.started": "2025-04-11T15:22:04.080660Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    logits = model(batch[0].to(device))\n",
    "pr_masks = (logits.squeeze(1) > 0.5).float()\n",
    "\n",
    "for image, gt_mask, pr_mask in zip(batch[0], batch[1], pr_masks):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image.numpy().transpose(1, 2, 0))  # convert CHW -> HWC\n",
    "    plt.title(\"Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(gt_mask.numpy().squeeze(), cmap = 'gray') # just squeeze classes dim, because we have only one class\n",
    "    plt.title(\"Ground truth\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pr_mask.detach().cpu().numpy()) # just squeeze classes dim, because we have only one class\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:05.225426Z",
     "iopub.status.busy": "2025-04-11T15:22:05.225021Z",
     "iopub.status.idle": "2025-04-11T15:22:06.408227Z",
     "shell.execute_reply": "2025-04-11T15:22:06.407246Z",
     "shell.execute_reply.started": "2025-04-11T15:22:05.225385Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    logits = model(batch[0].to(device))\n",
    "pr_masks = (logits.squeeze(1) > 0.5).float()\n",
    "\n",
    "for image, gt_mask, pr_mask in zip(batch[0], batch[1], pr_masks):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image.numpy().transpose(1, 2, 0))  # convert CHW -> HWC\n",
    "    plt.title(\"Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(gt_mask.numpy().squeeze(), cmap = 'gray') # just squeeze classes dim, because we have only one class\n",
    "    plt.title(\"Ground truth\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pr_mask.detach().cpu().numpy()) # just squeeze classes dim, because we have only one class\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:06.409669Z",
     "iopub.status.busy": "2025-04-11T15:22:06.409386Z",
     "iopub.status.idle": "2025-04-11T15:22:07.573142Z",
     "shell.execute_reply": "2025-04-11T15:22:07.572125Z",
     "shell.execute_reply.started": "2025-04-11T15:22:06.409645Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    logits = model(batch[0].to(device))\n",
    "pr_masks = (logits.squeeze(1) > 0.5).float()\n",
    "\n",
    "for image, gt_mask, pr_mask in zip(batch[0], batch[1], pr_masks):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image.numpy().transpose(1, 2, 0))  # convert CHW -> HWC\n",
    "    plt.title(\"Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(gt_mask.numpy().squeeze(), cmap = 'gray') # just squeeze classes dim, because we have only one class\n",
    "    plt.title(\"Ground truth\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pr_mask.detach().cpu().numpy()) # just squeeze classes dim, because we have only one class\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"list-group-item list-group-item-action active\" style=\"color:#0000FF;background-color:white;font-size:25px\">Better Loss Model</span> <a id=6></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:07.574846Z",
     "iopub.status.busy": "2025-04-11T15:22:07.574442Z",
     "iopub.status.idle": "2025-04-11T15:22:07.667775Z",
     "shell.execute_reply": "2025-04-11T15:22:07.667059Z",
     "shell.execute_reply.started": "2025-04-11T15:22:07.574810Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('/kaggle/working/model.bin'))\n",
    "model.load_state_dict(torch.load('/kaggle/working/model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:07.668735Z",
     "iopub.status.busy": "2025-04-11T15:22:07.668516Z",
     "iopub.status.idle": "2025-04-11T15:22:08.852400Z",
     "shell.execute_reply": "2025-04-11T15:22:08.851331Z",
     "shell.execute_reply.started": "2025-04-11T15:22:07.668717Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    logits = model(batch[0].to(device))\n",
    "pr_masks = (logits.squeeze(1) > 0.5).float()\n",
    "\n",
    "for image, gt_mask, pr_mask in zip(batch[0], batch[1], pr_masks):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image.numpy().transpose(1, 2, 0))  # convert CHW -> HWC\n",
    "    plt.title(\"Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(gt_mask.numpy().squeeze(), cmap = 'gray') # just squeeze classes dim, because we have only one class\n",
    "    plt.title(\"Ground truth\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pr_mask.detach().cpu().numpy()) # just squeeze classes dim, because we have only one class\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:08.853636Z",
     "iopub.status.busy": "2025-04-11T15:22:08.853357Z",
     "iopub.status.idle": "2025-04-11T15:22:10.390966Z",
     "shell.execute_reply": "2025-04-11T15:22:10.390219Z",
     "shell.execute_reply.started": "2025-04-11T15:22:08.853600Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    logits = model(batch[0].to(device))\n",
    "pr_masks = (logits.squeeze(1) > 0.5).float()\n",
    "\n",
    "for image, gt_mask, pr_mask in zip(batch[0], batch[1], pr_masks):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image.numpy().transpose(1, 2, 0))  # convert CHW -> HWC\n",
    "    plt.title(\"Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(gt_mask.numpy().squeeze(), cmap = 'gray') # just squeeze classes dim, because we have only one class\n",
    "    plt.title(\"Ground truth\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pr_mask.detach().cpu().numpy()) # just squeeze classes dim, because we have only one class\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:10.391948Z",
     "iopub.status.busy": "2025-04-11T15:22:10.391729Z",
     "iopub.status.idle": "2025-04-11T15:22:11.506134Z",
     "shell.execute_reply": "2025-04-11T15:22:11.505140Z",
     "shell.execute_reply.started": "2025-04-11T15:22:10.391929Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(test_loader))\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    logits = model(batch[0].to(device))\n",
    "pr_masks = (logits.squeeze(1) > 0.5).float()\n",
    "\n",
    "for image, gt_mask, pr_mask in zip(batch[0], batch[1], pr_masks):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image.numpy().transpose(1, 2, 0))  # convert CHW -> HWC\n",
    "    plt.title(\"Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(gt_mask.numpy().squeeze(), cmap = 'gray') # just squeeze classes dim, because we have only one class\n",
    "    plt.title(\"Ground truth\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pr_mask.detach().cpu().numpy()) # just squeeze classes dim, because we have only one class\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:11.507456Z",
     "iopub.status.busy": "2025-04-11T15:22:11.507158Z",
     "iopub.status.idle": "2025-04-11T15:22:11.512528Z",
     "shell.execute_reply": "2025-04-11T15:22:11.511701Z",
     "shell.execute_reply.started": "2025-04-11T15:22:11.507429Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Done!\")\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T15:22:11.513753Z",
     "iopub.status.busy": "2025-04-11T15:22:11.513433Z",
     "iopub.status.idle": "2025-04-11T15:22:11.528360Z",
     "shell.execute_reply": "2025-04-11T15:22:11.527375Z",
     "shell.execute_reply.started": "2025-04-11T15:22:11.513719Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pkg_resources\n",
    "\n",
    "# installed_packages = pkg_resources.working_set\n",
    "# for package in installed_packages:\n",
    "#     print(f\"{package.key}=={package.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 3495119,
     "sourceId": 27923,
     "sourceType": "competition"
    },
    {
     "datasetId": 181273,
     "sourceId": 407317,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 519333,
     "sourceId": 1370629,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
